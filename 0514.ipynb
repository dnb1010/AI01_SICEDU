{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOr8Spxv2Oiwu5IulQYA3H6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZTohHuN8vbOp"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import warnings\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets.reuters import load_data, get_word_index       # Reuters news data.\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Embedding\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n","warnings.filterwarnings('ignore')                  # Turn the warnings off.\n","%matplotlib inline"]},{"cell_type":"markdown","source":["1.1 Read in the data:"],"metadata":{"id":"kxTT73BYw7iQ"}},{"cell_type":"code","source":["n_words = 1000                                        # Size of the vocabulary.\n","(X_train, y_train), (X_test, y_test) = load_data(num_words = n_words, test_split = 0.3)\n","n_train_size = X_train.shape[0]"],"metadata":{"id":"G1I0tsYLxR74"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check for the shapes.\n","print(\"-\"*50)\n","print(\"Training data X shape: {}\".format(X_train.shape))\n","print(\"Training data y shape: {}\".format(y_train.shape))\n","print(\"-\"*50)\n","print(\"Test data X shape: {}\".format(X_test.shape))\n","print(\"Test data y shape: {}\".format(y_test.shape))\n","print(\"-\"*50)"],"metadata":{"id":"lQV1fPDL0fq4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.2 Explore the data"],"metadata":{"id":"E36eu3jEH6YR"}},{"cell_type":"code","source":["# Number of unique values of y = Number of categories of the newswires.\n","n_cat = pd.Series(y_train).nunique()\n","n_cat"],"metadata":{"id":"rhNV1NzF1V0_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print out an observation (document) contained in X\n","# It is encoded as integers (indices)\n","print(X_train[0])"],"metadata":{"id":"TbaL1g7sIFN6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's check for length of the first 100 documents.\n","# We notice that the length is not uniform\n","print([len(a) for a in X_train[0:100]])"],"metadata":{"id":"NYJQRJnfIatS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download the dictionary to translate the indices\n","my_dict = get_word_index(path = 'reuters_word_index.json')\n"],"metadata":{"id":"lg7Tef8tInl-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To view the dictionary\n","# my_dict"],"metadata":{"id":"iFAx-BffIwOZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Exchange the 'key' and 'value'\n","my_dict_inv = {v:k for k, v in my_dict.items()}"],"metadata":{"id":"n5VYiyX9I1xI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Translate each document\n","i_news = 10\n","news = list(pd.Series(X_train[i_news]).apply(lambda x: my_dict_inv[x]))\n","print(' '.join(news))"],"metadata":{"id":"nNTAYM3RI9dC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.3 Data preprocessing:"],"metadata":{"id":"F2nb9zeIJLUr"}},{"cell_type":"code","source":["# Padding: newswire lengths are uniformly matched to maxlen\n","# Cut away if longer than maxlen and fill with 0s if shorter than maxlen\n","X_train = sequence.pad_sequences(X_train, maxlen = 100)\n","X_test = sequence.pad_sequences(X_test, maxlen = 100)"],"metadata":{"id":"QVX4u5LqJI6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply one-hot-encoding to the y variable\n","y = np.concatenate([y_train, y_test], axis = 0)\n","y = to_categorical(y, 46)\n","y_train = y[:n_train_size, :]\n","y_test = y[n_train_size:, :]"],"metadata":{"id":"cA_9SajkJeZG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.4 Define the model"],"metadata":{"id":"dtM2OAz7JwTi"}},{"cell_type":"code","source":["n_neurons = 100 # Neurons within each memory cell\n","n_input = 100 # Dimension of the embeding space"],"metadata":{"id":"8ZdbhsvGJvAG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LSTM network model.\n","my_model = Sequential()\n","my_model.add(Embedding(n_words, n_input))\n","my_model.add(LSTM(units = n_neurons, return_sequences = False, input_shape = (None, n_input), activation='tanh'))\n","my_model.add(Dense(46, activation = 'softmax'))\n"],"metadata":{"id":"oprvX2UPJ6_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_model.summary()"],"metadata":{"id":"m8fyicFnKVaP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.5 Define the optimizer and compile"],"metadata":{"id":"1TTbrtZNKbsb"}},{"cell_type":"code","source":["n_epochs = 5 # Number of epochs\n","batch_size = 64 # Size of each batch.\n","learn_rate = 0.001 # Learning rate\n"],"metadata":{"id":"roX7SKdLKX5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optimizer and compilation.\n","my_optimizer = Adam(learning_rate = learn_rate)\n","my_model.compile(loss = 'categorical_crossentropy', optimizer = my_optimizer, metrics = ['accuracy'])"],"metadata":{"id":"oaIfdkhDKp-Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.6 Train the model and visualize the history"],"metadata":{"id":"LyKKeiLXK4tN"}},{"cell_type":"code","source":["my_summary = my_model.fit(X_train, y_train, epochs = n_epochs, batch_size = batch_size, validation_split = 0.2, verbose=1)"],"metadata":{"id":"nnRMl1s-KzrQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(my_summary.history['accuracy'], c=\"b\")\n","plt.plot(my_summary.history['val_accuracy'], c = \"g\")\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc ='lower right')\n","plt.show()"],"metadata":{"id":"5QAkXRYULDVW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.7 Testing"],"metadata":{"id":"Q4vURg0iL2hO"}},{"cell_type":"code","source":["ACC = my_model.evaluate(X_test, y_test, verbose = 0)\n","print(\"Test accuracy: {}\".format(np.round(ACC,3)))"],"metadata":{"id":"YlFRpKSbL2ML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"t0VLJiDWLtW8"},"execution_count":null,"outputs":[]}]}